## Credits
# https://github.com/mathiasbynens/dotfiles/blob/main/.functions
# https://github.com/junian/dotfiles/blob/master/.functions
# https://github.com/holman/dotfiles/tree/master/functions
##

# Update dotfiles
dfu() {
  (
    cd ~/.dotfiles && git pull --ff-only && ./install -q
  )
}

# `o` with no arguments opens the current directory, otherwise opens the given
# location (file explorer)
function o() {
  if [ $# -eq 0 ]; then
    open .
  else
    open "$@"
  fi
}

# Create a directory and cd into it
mcd() {
  mkdir "${1}" && cd "${1}"
}

# Create a .tar.gz archive, using `zopfli`, `pigz` or `gzip` for compression
function targz() {
  local tmpFile="${@%/}.tar"
  tar -cvf "${tmpFile}" --exclude=".DS_Store" "${@}" || return 1

  size=$(
    stat -f"%z" "${tmpFile}" 2>/dev/null # macOS `stat`
    stat -c"%s" "${tmpFile}" 2>/dev/null # GNU `stat`
  )

  local cmd=""
  if ((size < 52428800)) && hash zopfli 2>/dev/null; then
    # the .tar file is smaller than 50 MB and Zopfli is available; use it
    cmd="zopfli"
  else
    if hash pigz 2>/dev/null; then
      cmd="pigz"
    else
      cmd="gzip"
    fi
  fi

  echo "Compressing .tar ($((size / 1000)) kB) using \`${cmd}\`â€¦"
  "${cmd}" -v "${tmpFile}" || return 1
  [ -f "${tmpFile}" ] && rm "${tmpFile}"

  zippedSize=$(
    stat -f"%z" "${tmpFile}.gz" 2>/dev/null # macOS `stat`
    stat -c"%s" "${tmpFile}.gz" 2>/dev/null # GNU `stat`
  )

  echo "${tmpFile}.gz ($((zippedSize / 1000)) kB) created successfully."
}

# Usage: extract <file>
# Description: extracts archived files / mounts disk images
# Note: .dmg/hdiutil is macOS-specific.
#
# credit: http://nparikh.org/notes/zshrc.txt
extract() {
  if [ -f $1 ]; then
    case $1 in
    *.tar.bz2) tar -jxvf $1 ;;
    *.tar.gz) tar -zxvf $1 ;;
    *.bz2) bunzip2 $1 ;;
    *.dmg) hdiutil mount $1 ;;
    *.gz) gunzip $1 ;;
    *.tar) tar -xvf $1 ;;
    *.tbz2) tar -jxvf $1 ;;
    *.tgz) tar -zxvf $1 ;;
    *.zip) unzip $1 ;;
    *.ZIP) unzip $1 ;;
    *.pax) cat $1 | pax -r ;;
    *.pax.Z) uncompress $1 --stdout | pax -r ;;
    *.rar) unrar x $1 ;;
    *.Z) uncompress $1 ;;
    *) echo "'$1' cannot be extracted/mounted via extract()" ;;
    esac
  else
    echo "'$1' is not a valid file"
  fi
}

# Determine size of a file or total size of a directory
function fs() {
  if du -b /dev/null >/dev/null 2>&1; then
    local arg=-sbh
  else
    local arg=-sh
  fi
  if [[ -n "$@" ]]; then
    du $arg -- "$@"
  else
    du $arg .[^.]* ./*
  fi
}

# Function to list top n directories by size. If no argument is given, it lists top 10. Negative numbers list smallest n.
lsfs() {
    n=${1:-10} # Default to 10 if no argument is provided
    if (( $n < 0 )); then
        n=$(( -$n ))
        du -ah | sort -h | head -n $n
    else
        du -ah | sort -hr | head -n $n
    fi
}

# Compare original and gzipped file size
function gz() {
  local origsize=$(wc -c <"$1")
  local gzipsize=$(gzip -c "$1" | wc -c)
  local ratio=$(echo "$gzipsize * 100 / $origsize" | bc -l)
  printf "orig: %d bytes\n" "$origsize"
  printf "gzip: %d bytes (%2.2f%%)\n" "$gzipsize" "$ratio"
}

# tre: show a colorized, dirs-first tree including hidden files, excluding .git plus patterns from .gitignore and ~/.gitignore_global; paginated via less
tre() {
  # find project .gitignore (fall back to cwd)
  local root; root=$(git rev-parse --show-toplevel 2>/dev/null) || root="$PWD"
  local proj_ign="$root/.gitignore"
  local glob_ign=$(git config --get core.excludesfile | sed "s|^~|$HOME|" || echo "$HOME/.gitignore_global")
  # read, clean, join patterns
  local patterns
  patterns=$(
    grep -hEv '^\s*(#|$)' "$proj_ign" "$glob_ign" 2>/dev/null \
      | sed -E 's@^\./@@; s@/$@@; s@^\*\*/@@' \
      | paste -sd'|' -
  )
  # build -I argument (always ignore .git)
  if [[ -n $patterns ]]; then
    patterns=".git|$patterns"
  else
    patterns=".git"
  fi
  tree -aC -I "$patterns" --dirsfirst "$@" | less -FRNX
}

# TODO, needs fixing: https://github.com/conda/conda/issues/7980
## Disallow installing packages in base environment https://stackoverflow.com/a/69617319/17777085
#function pip() {
#  if [ "${CONDA_PROMPT_MODIFIER-}" = "(base) " ] && [ "$1" = "install" ]; then
#    echo "Not allowed in base"
#  else
#    command pip "$@"
#  fi
#}
#
#function extended_conda() {
#  if [ "${CONDA_PROMPT_MODIFIER-}" = "(base) " ] && [ "$1" = "install" ]; then
#    echo "Not allowed in base"
#  else
#    ~/miniconda/bin/conda "$@"
#  fi
#}
#alias conda=extended_conda
## End of disallow installing packages in base environment

# Change the ssh passphrase of given ssh key
function newsshpwd() {
    echo "Available ssh keys:"
    ls ~/.ssh | grep id_
    ssh-keygen -p -f ~/.ssh/$1
}

# Get the number of files in the current directory
function numel() {
    echo $(ls -1 | wc -l)
}

function count() {
    "$@" | wc -l
}

function choochoo() {
    while true; do
        sl
        clear
    done
}


function tailmail() {
    local user_mail="${1:-max}"
    tac "/var/mail/$user_mail" | sed "/^From /q" | tac
}

### Restic ... requires RESTIC_REPO & RESTIC_PASSWORD(_FILE) to be set

# Show the diff between the latest two snapshots of restic repository
# https://forum.restic.net/t/how-can-i-see-the-delta-between-two-snapshots/5258/4
function restic_diff() {
    restic diff --no-lock $(restic snapshots --no-lock --json --latest 2 | jq --raw-output 'map(.id) | .[-2:] | join(" ")') "$@"
}
# show the n biggest files within a restic repo; default 10
function restic_lsfs() {
    local n=${1:-10}
    restic ls --json latest | jq -r 'select(.type == "file") | [.path, .size] | @tsv' | sort -k2 -n -r | head -n "$n" | awk -F'\t' '{printf "%s\t%.2f MB\n", $1, $2/1048576}'
}

# put the content of a file into the clipboard, or read from stdin if no file is provided
clip() {
    if [ -z "$1" ]; then
        xclip -selection clipboard
    else
        xclip -selection clipboard < "$1"
    fi
}


# recursively cat the content of a directory (default current)
function rcat() {
    local dir=${1:-.}
    find "$dir" -type f -exec cat {} \;
} 

# recursively flatten a directory structure (defalt current dir), skip files with the same name
function flatten() {
    local dir=${1:-.}
    find "$dir" -mindepth 2 -type f -exec mv -n -t "$dir" {} +
}

# convert a website to markdown and store it to a file in my archive using markdowner
function archive_md() {
    local url="$1"
    local archive_dir="$HOME/Documents/archive/web"
    local filename="${url//[^a-zA-Z0-9]/_}.md"
    #   TODO: optional parameters for subpages, etc.
    curl -s 'https://md.dhr.wtf/?url='"$url" -H 'Content-Type: text/plain' > "$archive_dir/$filename"
    echo "$archive_dir/$filename"
}

# for educational purposes only; use at your own discretion!
# watchy <url>              # default: 2K quality, *marks* sponsors
# watchy <url> best         # best quality available
# watchy <url> fhd sblock   # 1080p max, *removes* sponsors  
# watchy <url> hd noblock   # 720p max, no sponsorblock
watchy() {
    local url="$1"
    local format="bv[height<=1440]+ba/b[height<=1440]"  # Default to 2K
    local sb=('--sponsorblock-mark' 'all')
    local auth=('--cookies-from-browser' 'firefox' '--user-agent' 'Mozilla/5.0')

    # Quality selection  
    [ "$2" = "best" ] && format="bv*+ba/b"
    [ "$2" = "4k" ] && format="bv[height<=2160]+ba/b[height<=2160]"
    [ "$2" = "2k" ] && format="bv[height<=1440]+ba/b[height<=1440]"
    [ "$2" = "fhd" ] && format="bv[height<=1080]+ba/b[height<=1080]"
    [ "$2" = "hd" ] && format="bv[height<=720]+ba/b[height<=720]"
    [ "$2" = "sd" ] && format="bv[height<=480]+ba/b[height<=480]"
    
    # Sponsorblock flags
    [ "$3" = "sblock" ] && sb=('--sponsorblock-remove' 'all')
    [ "$3" = "noblock" ] && sb=()
    
    # Browser flag
    [ -n "$4" ] && auth=('--cookies-from-browser' "$4" '--user-agent' 'Mozilla/5.0')

    yt-dlp "${auth[@]}" "${sb[@]}" -f "$format" \
        -o "$HOME/Downloads/%(title)s.%(ext)s" "$url" && \
        xdg-open "$HOME/Downloads/$(yt-dlp --get-filename -o "%(title)s.%(ext)s" "$url")"
}

latest_notes() {
    local num_notes=${1:-20}
    knb && cd Obsidian/scripts && uv run --script get_fnames.py -m && head filenames.txt -n "$num_notes"
    knb
}

unpublished_notes() {
    local num_notes=${1:-20}
    local whitelist_file="/home/max/repos/obsidian/knowledge-base/whitelist.json"
    local blacklist_file="/home/max/repos/obsidian/knowledge-base/blacklist.txt"
    
    # Save current directory and navigate to knowledge base
    local original_dir=$(pwd)
    cd ~/repos/obsidian/knowledge-base/Obsidian/scripts
    
    # Generate file list
    uv run --script get_fnames.py -m
    
    # Process in a single pipeline
    sed 's/^"//; s/",$//; s/",$//' filenames.txt | \
    grep -Fxvf <(jq -r '.files[]' "$whitelist_file" 2>/dev/null) | \
    { [[ -f "$blacklist_file" ]] && grep -vf <(grep -v '^#' "$blacklist_file" | grep -v '^[[:space:]]*$') || cat; } | \
    head -n "$num_notes" | \
    while IFS= read -r line; do echo "\"$line\","; done
    
    # Return to original directory
    cd "$original_dir"
}

fext() {
    local limit="${1:-50}"
    local dir="${2:-.}"
    
    find "$dir" -type f -exec du -b {} + 2>/dev/null | while read size path; do 
        base=${path:t}
        [[ "$base" =~ '\.' ]] && ext="${base##*.}" || ext="no_ext"
        echo "$size $ext"
    done | awk '{total[$2]+=$1} END {for (e in total) printf "%.0f %s\n", total[e], e}' | \
    sort -rn | head -n "$limit" | while read size ext; do 
        printf "%10s  .%s\n" "$(numfmt --to=iec-i --suffix=B $size)" "$ext"
    done
}
